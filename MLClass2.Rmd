---
title: "Assignment - Machine Learning (Classification))"
author: "Dr Mohd Azmi P-UD 0079/19"
date: '`r format(Sys.Date(), "%d %B, %Y")`'
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_float:
      collapsed: false
    number_sections: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F)
options(qwraps2_markup = "markdown", knitr.kable.NA = '')
```

https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/ - to update dataset, usinng normalize/standardize value

# Motivation

The dataset is taken from National Burn Repository 2007 Report (Hosmer, 2013). In this study, they record the hospital discharge status, patient's gender, patient's ethnicity, total burn surface area, inhalation injury and flame involvement. 1,000 data were collected (from total of 40,000 original data) in the dataset, BURN1000, which oversampled patient who died in hospital and undersampled subject who lived.

In this study, we would like to ascertain factors associated with death upon discharge among the burn injury patient. 

# Environment

## Packages

```{r}
library(pacman) # package manager, elegant way to load packages
p_load(tidyverse, haven, DT, rpart, summarytools, broom, caret, neuralnet, plyr, rpart.plot, knitr)
set.seed(119)
```

## Dataset & Data Exploration

Below are the data from the dataset

```{r}
burnDS0 <- read.delim("BURN1000.txt", header = TRUE, sep = "\t", dec = ".")

burnDS1 <- burnDS0 %>%
  mutate(DcStat = factor(DEATH, labels = c("Alive", "Death")), Gender = GENDER, Ethnic = RACEC, Inhale = INH_INJ, Flame = FLAME) %>%
  select(DcStat, AGE, Gender, Ethnic, TBSA, Inhale, Flame)

burnDS2 <- burnDS0 %>%
  mutate(DcStat = factor(DEATH, labels = c("Alive", "Death")),
         Gender = factor(GENDER, labels = c("Female", "Male")),
         Ethnic = factor(RACEC, labels = c("Non-white", "White")),
         Inhale = factor(INH_INJ, labels = c("No", "Yes")),
         Flame = factor(FLAME, labels = c("No", "Yes"))) %>%
  select(DcStat, AGE, Gender, Ethnic, TBSA, Inhale, Flame)

burnDS2 %>% datatable()
```

the dataset was split into training dataset and test dataset. the seed was set at 119.

```{r}
sRow <- sample(nrow(burnDS2), nrow(burnDS2)*.7)

burnDS2_train <- burnDS2[sRow,]
burnDS2_test <- burnDS2[-sRow,]
```



# Descriptive Analysis

## Data Summary

The median age of the participant was 31.95 years old (IQR = 49.38), while the median total burn surface area among the participant was 6% (IQR = 13.5%). Most of the participant was male (n = 705), white ethnicity (n = 589), had no inhalation injury (n = 878) and had flame involvement (n = 529)

```{r}
summary(burnDS2)
```

The distribution of each variable, grouped by discharge status, shown as below

```{r, message=F}
ggplot(burnDS2, aes(x=AGE)) + geom_histogram() + facet_wrap(~DcStat)
ggplot(burnDS2, aes(x=TBSA)) + geom_histogram() + facet_wrap(~DcStat)
ggplot(burnDS2, aes(x=Gender, fill=Gender)) + geom_bar() + facet_wrap(~DcStat)
ggplot(burnDS2, aes(x=Ethnic, fill=Ethnic)) + geom_bar() + facet_wrap(~DcStat)
ggplot(burnDS2, aes(x=Inhale, fill=Inhale)) + geom_bar() + facet_wrap(~DcStat)
ggplot(burnDS2, aes(x=Flame, fill=Flame)) + geom_bar() + facet_wrap(~DcStat)
```

# Machine Learning

two type of machine learning will be use to predict the outcome (alive vs death)

1. Decision Tree
2. Artificial Neural Network

both of the method will be compared by calculating their accuracy.


## Machine Learning - Decision Tree

### Decision Tree Model

Using train dataset, the decision tree was as shown below. 


```{r}
burnDS_dtmod <- rpart(DcStat ~ ., data = burnDS2_train, method = "class", parms = list(split = "information"))
rpart.plot(burnDS_dtmod, type = 1, yesno=2, digits = 4)
```


Note: Each node shows

1. the predicted outcome (Alive or Death)
2. the predicted probability of Death
3. the percentage of observations in the node

### Prediction

the model were tested using test dataset to predict the outcome, as shown below.

```{r}
burnDS2_test_dtpred <- predict(burnDS_dtmod, newdata = burnDS2_test, type = "class")
burnDS2_test_dtpredcomb <- tibble(burnDS2_test, Predicted = burnDS2_test_dtpred)
burnDS2_test_dtpredcomb %>% select(DcStat, Predicted, everything()) %>% datatable()
```



### Model Evaluation

The model was evaluate with test dataset.

```{r}
dteval_res <- confusionMatrix(burnDS2_test_dtpredcomb$Predicted, burnDS2_test_dtpredcomb$DcStat, positive = "Death")
dteval_res
```

The model had good accuracy with `r round((dteval_res$overall['Accuracy'])*100,1)`% and high specificity (`r round((dteval_res$byClass['Specificity'])*100,1)`%), but with lower sensitivity (`r round((dteval_res$byClass['Sensitivity'])*100,1)`%).


### 10-fold cross validation

The model was done with 10-fold cross validation

```{r}
k <- 10
dtaccuracy <- rep(NA, k)
folds <- split(burnDS2, cut(1:nrow(burnDS2),10))

for (i in 1:k) {
  test = ldply(folds[i], data.frame)
  train = ldply(folds[-i], data.frame)
  
  test$.id = NULL
  train$.id = NULL

  dtmodel <- rpart(DcStat ~ ., data = train, method = "class", parms = list(split = "information"))
  
  dtresults <- predict(dtmodel, test, type = "class")
  
  dtconfmat <- table(dtresults, test$DcStat)
  dtaccuracy[i] <- sum(diag(dtconfmat))/sum(dtconfmat)
}
```

The 10-fold cross validation show accuracy of `r sprintf("%1.1f%%", 100*dtaccuracy)` for each of the fold respectively. the average accuracy was `r sprintf("%1.1f%%", 100*mean(dtaccuracy))`

## Machine Learning - Artificial Neural Network

### Artificial Neural Network Model

Using train dataset, the Artificial Neural Network Model was as shown below


```{r}
burnDS1_train <- burnDS1[sRow,]
burnDS1_test <- burnDS1[-sRow,]

burnDS_annmod <- neuralnet(DcStat ~ AGE + Gender + Ethnic + TBSA + Inhale + Flame, data = burnDS1_train, hidden=2, linear.output = FALSE)
plot(burnDS_annmod, rep = "best")
```

the model were tested using test dataset to predict the outcome, as shown below.

### Prediction

```{r}
burnDS1_test_annpred0 <- predict(burnDS_annmod, burnDS1_test, type = "class")

burnDS1_test_annpred1 <- apply(burnDS1_test_annpred0, 1, which.max)
burnDS1_test_annpred1[burnDS1_test_annpred1==1]='Alive'
burnDS1_test_annpred1[burnDS1_test_annpred1==2]='Death'


burnDS1_test_annpredcomb <- tibble(burnDS1_test, Predicted = as.factor(burnDS1_test_annpred1)) %>%
  mutate(DcStat = as.factor(DcStat))
burnDS1_test_annpredcomb %>% select(DcStat, Predicted, everything()) %>% datatable()
```

### Model Evaluation

The model was evaluated using test dataset

```{r}
anneval_res <- confusionMatrix(burnDS1_test_annpredcomb$Predicted, burnDS1_test_annpredcomb$DcStat, positive = "Death")
anneval_res
```


The model had good accuracy with `r round((anneval_res$overall['Accuracy'])*100,1)`%, high specificity (`r round((anneval_res$byClass['Specificity'])*100,1)`%), and high sensitivity (`r round((anneval_res$byClass['Sensitivity'])*100,1)`%).


### 10-fold cross validation

The model was done with 10-fold cross validation

```{r}
k <- 10
annaccuracy <- rep(NA, k)
folds <- split(burnDS1, cut(1:nrow(burnDS1),10))

for (i in 1:k) {
  test = ldply(folds[i], data.frame)
  train = ldply(folds[-i], data.frame)
  
  test$.id = NULL
  train$.id = NULL

  annmodel <- neuralnet(DcStat ~ AGE + Gender + Ethnic + TBSA + Inhale + Flame, data = train, hidden=1, linear.output = FALSE)

  annresults <- predict(annmodel, test, type = "class")
  
  annconfmat <- table(apply(annresults,1,which.max), test$DcStat)
  annaccuracy[i] <- sum(diag(annconfmat))/sum(annconfmat)
}

```

The 10-fold cross validation show accuracy of `r sprintf("%1.1f%%", 100*annaccuracy)` for each of the fold respectively. the average accuracy was `r sprintf("%1.1f%%", 100*mean(annaccuracy))`

## Comparison

To compare both model, the models were tested with new dataset which contain parameter as shown below

```{r}
newds2 <- expand.grid(AGE = c(20,80), Gender = 1, Ethnic = 1, TBSA = c(5,35), Inhale = 1, Flame = c(0,1))
newds2cat <- newds2 %>%
  mutate(Gender = factor(Gender, labels = "Male"),
         Ethnic = factor(Ethnic, labels = "White"),
         Inhale = factor(Inhale, labels = "Yes"),
         Flame = factor(Flame, labels = c("No", "Yes"))) %>%
  select(AGE, Gender, Ethnic, TBSA, Inhale, Flame) 
kable(newds2cat)
```

table below show the predicted outcome, for both decision tree model and artificial network.

```{r}
preddt <- predict(burnDS_dtmod, newds2cat, type = "class")

predann <- apply(predict(burnDS_annmod, newds2, type = "class"), 1, which.max)
predann[predann==1]='Alive'
predann[predann==2]='Death'

comres <- tibble(newds2cat, dtpred = as.factor(preddt), annpred = as.factor(predann))
kable(comres)
```


When comparing the 10-fold cross-validation, refer [link]() and [link](), artificial neural network had higher average accuracy, however there are some of the fold in the ann had 0% accuracy.


# Discussion

- which more accurate?

- why have different prediction


# Conclusion

# Reference


# Additional Info

```{r}

```




```{r}
sessionInfo()
```

